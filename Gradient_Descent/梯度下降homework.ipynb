{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"SimHei\"\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x1, x2):\n",
    "    return 0.2 * (x1 + x2) ** 2 - 0.3 * x1 * x2 + 0.4\n",
    "\n",
    "\n",
    "def grad_descent(f, x_init, eta=0.1, tol=1e-4, max_iter=1000, verbose=True):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    x1, x2 = x_init\n",
    "    for i in range(max_iter):\n",
    "        x_list.append((x1, x2))\n",
    "        y = f(x1, x2)\n",
    "        y_list.append(y)\n",
    "        if len(y_list) >= 2 and y_list[-2] - y_list[-1] < tol:\n",
    "            break\n",
    "            \n",
    "        delt = 1e-3\n",
    "        g1 = (f(x1 + delt, x2) - f(x1, x2))/delt\n",
    "        g2 = (f(x1, x2 + delt) - f(x1, x2))/delt\n",
    "        x1 -= eta * g1\n",
    "        x2 -= eta * g2\n",
    "        \n",
    "    if verbose:\n",
    "        for index, (a, b) in enumerate(zip(x_list, y_list), start=1):\n",
    "            print(f\"第{index}次迭代，x={a}, y={b}\")\n",
    "    return x_list, y_list\n",
    "\n",
    "x_list, y_list = grad_descent(fun, x_init=(4.8, 4.5), eta=0.01, verbose=False)\n",
    "\n",
    "\n",
    "def plot_result(f, x, x_li, y_li):\n",
    "    x1, x2 = x\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    X = np.array([X1.ravel(), X2.ravel()]).T\n",
    "    y = f(X[:, 0], X[:, 1])\n",
    "    Y = y.reshape(X1.shape)\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    surf = ax.plot_surface(X1, X2, Y, rstride=5, cstride=5, cmap=\"rainbow\", alpha=0.8)\n",
    "    # 将自变量的轨迹列表转换为ndarray数组，方便按列单独提取x1与x2的轨迹。\n",
    "    array = np.asarray(x_li)\n",
    "    x1_trace = array[:, 0]\n",
    "    x2_trace = array[:, 1]\n",
    "    ax.plot(x1_trace, x2_trace, y_list, c=\"b\", ls=\"--\", marker=\"o\")\n",
    "    ax.set_title(\"函数$y = 0.2(x1 + x2) ^ {2} - 0.3x1x2 + 0.4$\")\n",
    "    # 绘制三维图时，参数必须是数组类型，不支持标量，这点与绘制二维图不同。\n",
    "    ax.plot(x1_trace[0:1], x2_trace[0:1], y_list[0:1], marker=\"*\", ms=15, c=\"r\", label=\"初始点\")\n",
    "    ax.plot(x1_trace[-1:], x2_trace[-1:], y_list[-1:], marker=\"*\", ms=15, c=\"g\", label=\"终止点\")\n",
    "    # 为曲面对象增加颜色条。\n",
    "#     fig.colorbar(surf)\n",
    "    ax.legend()\n",
    "    # 创建新的画布，用来绘制等高线图。\n",
    "    fig2 = plt.figure()\n",
    "    ax2 = fig2.gca()\n",
    "    m = ax2.contourf(X1, X2, Y, 10)\n",
    "    ax2.scatter(x1_trace, x2_trace, c=\"r\")\n",
    "    # 为等高线图增加颜色条。\n",
    "    fig2.colorbar(m)\n",
    "    ax2.set_title(\"轨迹更新投影图\")\n",
    "    plt.show()\n",
    "\n",
    "edge = 10\n",
    "x1_domain = np.linspace(-edge, edge, 100)\n",
    "x2_domain = np.linspace(-edge, edge, 100)\n",
    "plot_result(fun, (x1_domain, x2_domain), x_list, y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二题&第三题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.512066578851029 [41.06483863 66.50721497 10.9424458  60.43148722 25.69384343]\n",
      "真实的系数: [41.20593377 66.49948238 10.71453179 60.19514224 25.96147771]\n",
      "0.9972551641628642\n",
      "0.9978527244815283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X, y, coef = make_regression(n_samples=1000, n_features=5, bias=2.5, coef=True, noise=5, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "\n",
    "class BatchGradDescent:\n",
    "    \"\"\"\n",
    "    批量梯度下降类\n",
    "    参数:\n",
    "    max_iter:最大迭代次数\n",
    "    eta: 学习率大小\n",
    "    n: 连续n次没有提升就退出迭代\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=1000, eta=1e-3, n=5):\n",
    "        self.max_iter = max_iter\n",
    "        self.eta = eta\n",
    "        self.n = n\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.w = np.random.random((X.shape[1] + 1, 1))\n",
    "        self.X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "        scores = []\n",
    "        flag = False\n",
    "        for itera in range(self.max_iter):\n",
    "            for i in range(self.X.shape[1]):\n",
    "                wi_gradient = 0\n",
    "                # 这里使用的是批量梯度下降\n",
    "                for j in range(0, len(self.X)):\n",
    "                    x_single = self.X[j]\n",
    "                    y_single = y[j]\n",
    "                    wi_gradient += -(y_single - x_single.dot(self.w)[0]) * self.X[j][i]\n",
    "                self.w[i][0] -= self.eta * wi_gradient\n",
    "            scores.append(self.score(X, y))\n",
    "            \n",
    "            if len(scores) >= self.n + 1:\n",
    "                for i in range(2, self.n + 2):\n",
    "                    # 如果最近n次, 其中一次有提升就继续\n",
    "                    if scores[-1] - scores[-i] > 0:\n",
    "                        continue\n",
    "                    # 如果都没有提升, 那就停止迭代\n",
    "                    if i == self.n + 1:\n",
    "                        flag = True\n",
    "            if flag:\n",
    "                break\n",
    "        self.intercept = self.w.ravel()[0]\n",
    "        self.coef = self.w[1:].ravel()\n",
    "        \n",
    "    \n",
    "    def predict(self, Xtest):\n",
    "        Xtest = np.concatenate([np.ones((Xtest.shape[0], 1)), Xtest], axis=1)\n",
    "        return Xtest.dot(self.w).ravel()\n",
    "    \n",
    "    def score(self, X_test, Y_test):\n",
    "        y_hat = self.predict(X_test)\n",
    "        return self.r_square(y_hat, Y_test)\n",
    "    \n",
    "    def r_square(self, y_hat, Y_test):\n",
    "        rss = np.sum(np.square(Y_test - y_hat))\n",
    "        tss = np.sum(np.square(Y_test - y_hat.mean()))\n",
    "        return 1 - rss/ tss\n",
    "\n",
    "bgd = BatchGradDescent(max_iter=1000, eta=1e-4, n=5)\n",
    "bgd.fit(X_train, y_train)\n",
    "print(bgd.intercept, bgd.coef)\n",
    "\n",
    "# 真实的系数\n",
    "print(\"真实的系数:\", coef)\n",
    "\n",
    "print(bgd.score(X_train, y_train))\n",
    "print(bgd.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
